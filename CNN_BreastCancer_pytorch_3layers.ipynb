{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # version 1.3.1\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CyclicLR\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# data augmentation\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageFilter\n",
    "\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# remove if not needed because augmentation is already applied \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# INSTALL tqdm for jupyter lab:\n",
    "# 1. pip install tqdm==4.36.1\n",
    "# 2. pip install ipywidgets\n",
    "# 3. jupyter nbextension enable --py widgetsnbextension\n",
    "# 4. jupyter labextension install @jupyter-widgets/jupyterlab-manager (installed nodejs and npm needed)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train_df = pd.read_json(\"dataframes/final_train_df.json\")\n",
    "loaded_val_df = pd.read_json(\"dataframes/val_df.json\")\n",
    "loaded_test_df = pd.read_json(\"dataframes/test_df.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10258</td>\n",
       "      <td>data/breast-histopathology-images/IDC_regular_...</td>\n",
       "      <td>0</td>\n",
       "      <td>801</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10258</td>\n",
       "      <td>data/breast-histopathology-images/IDC_regular_...</td>\n",
       "      <td>0</td>\n",
       "      <td>801</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10258</td>\n",
       "      <td>data/breast-histopathology-images/IDC_regular_...</td>\n",
       "      <td>0</td>\n",
       "      <td>851</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10258</td>\n",
       "      <td>data/breast-histopathology-images/IDC_regular_...</td>\n",
       "      <td>0</td>\n",
       "      <td>601</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10258</td>\n",
       "      <td>data/breast-histopathology-images/IDC_regular_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280827</th>\n",
       "      <td>9173</td>\n",
       "      <td>data/train_class1_augmented/9173_idx5_x2301_y1...</td>\n",
       "      <td>1</td>\n",
       "      <td>2301</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280828</th>\n",
       "      <td>13693</td>\n",
       "      <td>data/train_class1_augmented/13693_idx5_x551_y1...</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280829</th>\n",
       "      <td>13402</td>\n",
       "      <td>data/train_class1_augmented/13402_idx5_x1451_y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1451</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280830</th>\n",
       "      <td>16165</td>\n",
       "      <td>data/train_class1_augmented/16165_idx5_x1401_y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1401</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280831</th>\n",
       "      <td>14157</td>\n",
       "      <td>data/train_class1_augmented/14157_idx5_x1451_y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1451</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280832 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id                                         image_path  label  \\\n",
       "0            10258  data/breast-histopathology-images/IDC_regular_...      0   \n",
       "1            10258  data/breast-histopathology-images/IDC_regular_...      0   \n",
       "2            10258  data/breast-histopathology-images/IDC_regular_...      0   \n",
       "3            10258  data/breast-histopathology-images/IDC_regular_...      0   \n",
       "4            10258  data/breast-histopathology-images/IDC_regular_...      0   \n",
       "...            ...                                                ...    ...   \n",
       "280827        9173  data/train_class1_augmented/9173_idx5_x2301_y1...      1   \n",
       "280828       13693  data/train_class1_augmented/13693_idx5_x551_y1...      1   \n",
       "280829       13402  data/train_class1_augmented/13402_idx5_x1451_y...      1   \n",
       "280830       16165  data/train_class1_augmented/16165_idx5_x1401_y...      1   \n",
       "280831       14157  data/train_class1_augmented/14157_idx5_x1451_y...      1   \n",
       "\n",
       "           x     y  \n",
       "0        801  1151  \n",
       "1        801   951  \n",
       "2        851   651  \n",
       "3        601   951  \n",
       "4       1001   851  \n",
       "...      ...   ...  \n",
       "280827  2301  1601  \n",
       "280828   551  1551  \n",
       "280829  1451  1001  \n",
       "280830  1401  1501  \n",
       "280831  1451  1251  \n",
       "\n",
       "[280832 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CNN with 3 layers (see paper 2014 ..):\n",
    "\"Our system adapts a 3-layers CNN architecture employing 16, 32, and 128\n",
    "neurons, for the first and second convolutional-pooling layers and the fully-connected layer respectively. For all\n",
    "experiments, a fixed convolutional kernel of size 8×8 and pool kernel of size 2×2 were used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for model\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCHS = 8\n",
    "\n",
    "OUTPUT_PATH = \"\"\n",
    "MODEL_PATH = \"cnn_model/\"\n",
    "LOSSES_PATH = \"cnn_model/\"\n",
    "\n",
    "\n",
    "\n",
    "#run_training = True\n",
    "#retrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_transform(key=\"train_transform\"):\n",
    "    #boost class 1 in training set:\n",
    "    train_transform = [transforms.Resize((50, 50)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                    transforms.RandomRotation(90), \n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])]\n",
    "    \n",
    "    val_test_transform = [transforms.Resize((50, 50)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])]\n",
    "        \n",
    "    data_transforms = {'train_transform': transforms.Compose(train_transform), \n",
    "                       'val_test_transform': transforms.Compose(val_test_transform)}\n",
    "    return data_transforms[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.states = df\n",
    "        self.transform=transform\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.states.patient_id.values[idx]\n",
    "        x_coord = self.states.x.values[idx]\n",
    "        y_coord = self.states.y.values[idx]\n",
    "        image_path = self.states.image_path.values[idx] \n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('RGB') # try to convert to YUV instead of RGB later\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "         \n",
    "        label = np.int(self.states.label.values[idx])\n",
    "        return {\"image\": image,\n",
    "                \"label\": label,\n",
    "                \"patient_id\": patient_id,\n",
    "                \"x\": x_coord,\n",
    "                \"y\": y_coord}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BreastCancerDataset(loaded_train_df, transform=my_transform(key=\"train_transform\"))\n",
    "val_dataset = BreastCancerDataset(loaded_val_df, transform=my_transform(key=\"val_test_transform\"))\n",
    "test_dataset = BreastCancerDataset(loaded_test_df, transform=my_transform(key=\"val_test_transform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 280832, 'val': 37886, 'test': 43313}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!!!! calculate layer parameters\n",
    "class ThreeLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # ancestor constructor call\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=8, padding=2)\n",
    "    #     self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(512 * 1 * 1, 2) # !!!\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x)))) # first convolutional layer then batchnorm, then activation then pooling layer.\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "       \n",
    "        x = self.avg(x)\n",
    "        #print(x.shape) # lifehack to find out the correct dimension for the Linear Layer\n",
    "        x = x.view(-1, 512 * 1 * 1) # !!!\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BreastCancer",
   "language": "python",
   "name": "breastcancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
